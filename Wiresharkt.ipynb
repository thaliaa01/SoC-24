{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afb946-7ebf-4051-8969-025a7710ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import deque\n",
    "import random\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Step 1: Unzip the file\n",
    "data_path = \"C:/Users/singa/Downloads/archive (6).zip\"\n",
    "with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('extracted_files')\n",
    "\n",
    "# Step 2: Define column names and read the dataset\n",
    "columns = (['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    "            'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "            'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count',\n",
    "            'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "            'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "            'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "            'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'outcome', 'level'])\n",
    "\n",
    "train_data_path = 'extracted_files/KDDTrain+.txt'\n",
    "test_data_path = 'extracted_files/KDDTest+.txt'\n",
    "\n",
    "data_train = pd.read_csv(train_data_path, names=columns, header=None)\n",
    "data_test = pd.read_csv(test_data_path, names=columns, header=None)\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "def preprocess_data(data):\n",
    "    categorical_features = ['protocol_type', 'service', 'flag']\n",
    "    data = pd.get_dummies(data, columns=categorical_features)\n",
    "    \n",
    "    numerical_features = data.columns.difference(['outcome', 'level'])\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "    \n",
    "    return data\n",
    "\n",
    "data_train = preprocess_data(data_train)\n",
    "data_test = preprocess_data(data_test)\n",
    "\n",
    "X_train = data_train.drop(['outcome', 'level'], axis=1).values\n",
    "y_train = pd.get_dummies(data_train['outcome']).values\n",
    "X_test = data_test.drop(['outcome', 'level'], axis=1).values\n",
    "y_test = pd.get_dummies(data_test['outcome']).values\n",
    "\n",
    "# Step 4: Define the DDQN Agent\n",
    "class DDQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Discount rate\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(128, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * np.amax(self.target_model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Step 5: Train the Agent\n",
    "def train_agent(episodes):\n",
    "    agent = DDQNAgent(state_size=X_train.shape[1], action_size=y_train.shape[1])\n",
    "    batch_size = 32\n",
    "\n",
    "    for e in range(episodes):\n",
    "        for i in range(len(X_train)):\n",
    "            state = X_train[i].reshape(1, -1)\n",
    "            action = agent.act(state)\n",
    "            reward = 1 if np.argmax(y_train[i]) == action else -1\n",
    "            next_state = X_train[i].reshape(1, -1)\n",
    "            done = i == len(X_train) - 1\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "        agent.update_target_model()\n",
    "        print(f\"Episode {e+1}/{episodes} completed.\")\n",
    "\n",
    "# Step 6: Evaluate the Agent\n",
    "def evaluate_agent(agent):\n",
    "    correct_predictions = 0\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        state = X_test[i].reshape(1, -1)\n",
    "        action = agent.act(state)\n",
    "        predictions.append(action)\n",
    "        if np.argmax(y_test[i]) == action:\n",
    "            correct_predictions += 1\n",
    "    accuracy = correct_predictions / len(X_test)\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(np.argmax(y_test, axis=1), predictions))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    sns.heatmap(confusion_matrix(np.argmax(y_test, axis=1), predictions), annot=True, cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "# Train and Evaluate the Agent\n",
    "train_agent(episodes=100)\n",
    "evaluate_agent(agent)\n",
    "# Save the DDQN agent\n",
    "agent.model.save('ddqn_agent.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e62c0-86f6-4fac-946f-0a2278dba2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scapy.all import rdpcap, TCP, IP\n",
    "from collections import deque\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the function to extract features from a PCAP file\n",
    "def extract_features_from_pcap(pcap_file):\n",
    "    packets = rdpcap(pcap_file)\n",
    "    features = []\n",
    "\n",
    "    for pkt in packets:\n",
    "        if IP in pkt:\n",
    "            feature = {\n",
    "                'duration': pkt.time,  # Example of a simple feature\n",
    "                'protocol_type': pkt[IP].proto,\n",
    "                'src_bytes': len(pkt[IP].payload),\n",
    "                'dst_bytes': len(pkt[IP]),  # Example features\n",
    "                'flag': pkt[TCP].flags if TCP in pkt else 0,\n",
    "                # Add other features based on the KDD dataset structure\n",
    "            }\n",
    "            features.append(feature)\n",
    "\n",
    "    df = pd.DataFrame(features)\n",
    "    return df\n",
    "\n",
    "# Preprocessing for PCAP data\n",
    "def preprocess_pcap_data(pcap_df):\n",
    "    # Assuming the same categorical and numerical preprocessing as the KDD dataset\n",
    "    categorical_features = ['protocol_type', 'flag']\n",
    "    pcap_df = pd.get_dummies(pcap_df, columns=categorical_features)\n",
    "\n",
    "    numerical_features = pcap_df.columns.difference(['outcome', 'level'])\n",
    "    scaler = StandardScaler()\n",
    "    pcap_df[numerical_features] = scaler.fit_transform(pcap_df[numerical_features])\n",
    "\n",
    "    return pcap_df\n",
    "\n",
    "# Define the DDQN Agent\n",
    "class DDQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0   # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Network for Deep Q-learning\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(layers.Dense(24, activation='relu'))\n",
    "        model.add(layers.Dense(self.action_size, activation='linear'))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "# Integrate with DDQN agent for prediction\n",
    "def test_on_pcap(pcap_file, agent):\n",
    "    # Step 1: Extract features\n",
    "    pcap_df = extract_features_from_pcap(pcap_file)\n",
    "\n",
    "    # Step 2: Preprocess data\n",
    "    pcap_df = preprocess_pcap_data(pcap_df)\n",
    "\n",
    "    # Step 3: Prepare features (assuming no 'outcome' column in pcap data)\n",
    "    X_pcap = pcap_df.values\n",
    "\n",
    "    # Step 4: Predict using the trained DDQN model\n",
    "    predictions = []\n",
    "    for i in range(len(X_pcap)):\n",
    "        state = X_pcap[i].reshape(1, -1)\n",
    "        action = agent.act(state)\n",
    "        predictions.append(action)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Load the trained DDQN model (ensure it's loaded or trained before using)\n",
    "state_size = 41  # Adjust this according to your input feature size\n",
    "action_size = 5  # Adjust this according to your action space size\n",
    "\n",
    "agent = DDQNAgent(state_size, action_size)\n",
    "agent.load(\"path_to_trained_ddqn_model.h5\")  # Replace with your model's file path\n",
    "\n",
    "# Test the agent on a new PCAP file\n",
    "pcap_file = \"C:/Users/singa/OneDrive/ドキュメント/wireshark_capture.pcapng\"\n",
    "predictions = test_on_pcap(pcap_file, agent)\n",
    "\n",
    "# Example output\n",
    "print(\"Predictions for the PCAP file:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af69ea-edc1-404e-b16e-8cdb7f3ec702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
